{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad10a909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9149, 7)\n",
      "TF-IDF shape: (9149, 11742)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(r\"..\\data\\processed\\gutendex-cleaned-dataset_v3.csv\")\n",
    "\n",
    "tfidf_sparse = sparse.load_npz(r\"../models/tfidf_matrix.npz\")\n",
    "feature_names = np.load(r\"../models/tfidf_feature_names.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"TF-IDF shape:\", tfidf_sparse.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c37107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Mean Top-10 Similarity: 0.3228167287569576\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf = NearestNeighbors(n_neighbors=11, metric='cosine')\n",
    "knn_tfidf.fit(tfidf_sparse)\n",
    "\n",
    "distances_a, indices_a = knn_tfidf.kneighbors(tfidf_sparse)\n",
    "\n",
    "similarities_a = 1 - distances_a[:, 1:]\n",
    "mean_similarity_a = np.mean(similarities_a)\n",
    "\n",
    "print(\"Model A Mean Top-10 Similarity:\", mean_similarity_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96d31fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model B Mean Top-10 Similarity: 0.7293997731445321\n"
     ]
    }
   ],
   "source": [
    "svd_200 = TruncatedSVD(n_components=200, random_state=42)\n",
    "tfidf_reduced = svd_200.fit_transform(tfidf_sparse)\n",
    "\n",
    "knn_svd = NearestNeighbors(n_neighbors=11, metric='cosine')\n",
    "knn_svd.fit(tfidf_reduced)\n",
    "\n",
    "distances_b, indices_b = knn_svd.kneighbors(tfidf_reduced)\n",
    "\n",
    "similarities_b = 1 - distances_b[:, 1:]\n",
    "mean_similarity_b = np.mean(similarities_b)\n",
    "\n",
    "print(\"Model B Mean Top-10 Similarity:\", mean_similarity_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3c54dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Mean NDCG@10: 1.0\n",
      "Model B Mean NDCG@10: 0.9999995939442156\n"
     ]
    }
   ],
   "source": [
    "ndcg_scores_a = []\n",
    "ndcg_scores_b = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    true_relevance = similarities_a[i].reshape(1, -1)\n",
    "    predicted_scores_a = similarities_a[i].reshape(1, -1)\n",
    "    predicted_scores_b = similarities_b[i].reshape(1, -1)\n",
    "    \n",
    "    ndcg_scores_a.append(ndcg_score(true_relevance, predicted_scores_a))\n",
    "    ndcg_scores_b.append(ndcg_score(true_relevance, predicted_scores_b))\n",
    "\n",
    "print(\"Model A Mean NDCG@10:\", np.mean(ndcg_scores_a))\n",
    "print(\"Model B Mean NDCG@10:\", np.mean(ndcg_scores_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd979ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Avg Recommended Popularity: 2037.6629139796698\n",
      "Model B Avg Recommended Popularity: 1992.5407804131596\n"
     ]
    }
   ],
   "source": [
    "popularity_a = []\n",
    "popularity_b = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    rec_indices_a = indices_a[i][1:]\n",
    "    rec_indices_b = indices_b[i][1:]\n",
    "    \n",
    "    popularity_a.append(df.iloc[rec_indices_a]['download_count'].mean())\n",
    "    popularity_b.append(df.iloc[rec_indices_b]['download_count'].mean())\n",
    "\n",
    "print(\"Model A Avg Recommended Popularity:\", np.mean(popularity_a))\n",
    "print(\"Model B Avg Recommended Popularity:\", np.mean(popularity_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5450df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Similarity Std: 0.1403320799728983\n",
      "Model B Similarity Std: 0.11590120017997045\n"
     ]
    }
   ],
   "source": [
    "print(\"Model A Similarity Std:\", np.std(similarities_a))\n",
    "print(\"Model B Similarity Std:\", np.std(similarities_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a352ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Proper NDCG@10: 0.8523426806829285\n",
      "Model B Proper NDCG@10: 0.8533672185333697\n"
     ]
    }
   ],
   "source": [
    "def parse_subjects(s):\n",
    "    if pd.isna(s):\n",
    "        return set()\n",
    "    return set([x.strip().lower() for x in s.split(\",\")])\n",
    "\n",
    "subject_sets = df[\"subjects\"].apply(parse_subjects).tolist()\n",
    "\n",
    "def compute_ndcg(similarities, indices, k=10):\n",
    "    ndcg_scores = []\n",
    "    for i in range(len(df)):\n",
    "        rec_indices = indices[i][1:k+1]\n",
    "        true_relevance = []\n",
    "        predicted_scores = similarities[i][:k]\n",
    "        base_subjects = subject_sets[i]\n",
    "        for idx in rec_indices:\n",
    "            overlap = len(base_subjects.intersection(subject_sets[idx]))\n",
    "            true_relevance.append(1 if overlap > 0 else 0)\n",
    "        if sum(true_relevance) == 0:\n",
    "            continue\n",
    "        ndcg = ndcg_score([true_relevance], [predicted_scores])\n",
    "        ndcg_scores.append(ndcg)\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "ndcg_a = compute_ndcg(similarities_a, indices_a, k=10)\n",
    "ndcg_b = compute_ndcg(similarities_b, indices_b, k=10)\n",
    "\n",
    "print(\"Model A Proper NDCG@10:\", ndcg_a)\n",
    "print(\"Model B Proper NDCG@10:\", ndcg_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f0e2846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Baseline NDCG@10: 0.4518251620569098\n"
     ]
    }
   ],
   "source": [
    "def compute_random_ndcg(k=10):\n",
    "    ndcg_scores = []\n",
    "    all_indices = np.arange(len(df))\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        base_subjects = subject_sets[i]\n",
    "        random_indices = np.random.choice(all_indices[all_indices != i], size=k, replace=False)\n",
    "        \n",
    "        true_relevance = []\n",
    "        for idx in random_indices:\n",
    "            overlap = len(base_subjects.intersection(subject_sets[idx]))\n",
    "            true_relevance.append(1 if overlap > 0 else 0)\n",
    "        \n",
    "        if sum(true_relevance) == 0:\n",
    "            continue\n",
    "        \n",
    "        random_scores = np.random.rand(k)\n",
    "        ndcg = ndcg_score([true_relevance], [random_scores])\n",
    "        ndcg_scores.append(ndcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "random_ndcg = compute_random_ndcg(k=10)\n",
    "print(\"Random Baseline NDCG@10:\", random_ndcg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4687f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Hold-out NDCG@10: 0.8613488644808529\n",
      "Model B Hold-out NDCG@10: 0.8611998388150808\n"
     ]
    }
   ],
   "source": [
    "def compute_holdout_ndcg(similarities, indices, k=10):\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        subjects = list(subject_sets[i])\n",
    "        if len(subjects) < 2:\n",
    "            continue\n",
    "        \n",
    "        held_out = subjects[0]\n",
    "        remaining = set(subjects[1:])\n",
    "        \n",
    "        rec_indices = indices[i][1:k+1]\n",
    "        predicted_scores = similarities[i][:k]\n",
    "        \n",
    "        true_relevance = []\n",
    "        for idx in rec_indices:\n",
    "            overlap = held_out in subject_sets[idx]\n",
    "            true_relevance.append(1 if overlap else 0)\n",
    "        \n",
    "        if sum(true_relevance) == 0:\n",
    "            continue\n",
    "        \n",
    "        ndcg = ndcg_score([true_relevance], [predicted_scores])\n",
    "        ndcg_scores.append(ndcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "holdout_a = compute_holdout_ndcg(similarities_a, indices_a, k=10)\n",
    "holdout_b = compute_holdout_ndcg(similarities_b, indices_b, k=10)\n",
    "\n",
    "print(\"Model A Hold-out NDCG@10:\", holdout_a)\n",
    "print(\"Model B Hold-out NDCG@10:\", holdout_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8713196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_=pd.read_csv(r\"../data/processed/transformed_dataset_v1.csv\")\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.8)\n",
    "\n",
    "tfidf_sparse = tfidf_vectorizer.fit_transform(df_[\"combined_text\"])\n",
    "\n",
    "knn_tfidf = NearestNeighbors(n_neighbors=11, metric='cosine')\n",
    "knn_tfidf.fit(tfidf_sparse)\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, r\"../models/tfidf_vectorizer.pkl\")\n",
    "joblib.dump(knn_tfidf, r\"../models/knn_tfidf.pkl\")\n",
    "sparse.save_npz(r\"../models/tfidf_matrix.npz\", tfidf_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d63e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Book:\n",
      "Frankenstein; or, the modern prometheus\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model A (TF-IDF + KNN) Recommendations:\n",
      "\n",
      "1. Frankenstein; Or, The Modern Prometheus  |  Similarity: 0.8686\n",
      "2. The Last Man  |  Similarity: 0.3620\n",
      "3. The Vampyre; a Tale  |  Similarity: 0.3292\n",
      "4. Black magic : $b A tale of the rise and fall of Antichrist  |  Similarity: 0.3136\n",
      "5. Dracula  |  Similarity: 0.3081\n",
      "6. The Beetle: A Mystery  |  Similarity: 0.3030\n",
      "7. Northanger Abbey  |  Similarity: 0.2782\n",
      "8. The Life and Letters of Mary Wollstonecraft Shelley, Volume 1 (of 2)  |  Similarity: 0.2664\n",
      "9. A Princess of Mars  |  Similarity: 0.2553\n",
      "10. Wuthering Heights  |  Similarity: 0.2527\n",
      "\n",
      "Model B (SVD + KNN) Recommendations:\n",
      "\n",
      "1. Frankenstein; Or, The Modern Prometheus  |  Similarity: 0.9810\n",
      "2. The Last Man  |  Similarity: 0.8346\n",
      "3. Dracula  |  Similarity: 0.7924\n",
      "4. The colour out of space  |  Similarity: 0.7559\n",
      "5. At the mountains of madness  |  Similarity: 0.7249\n",
      "6. The shadow over Innsmouth  |  Similarity: 0.7157\n",
      "7. Anthem  |  Similarity: 0.7156\n",
      "8. Black magic : $b A tale of the rise and fall of Antichrist  |  Similarity: 0.7122\n",
      "9. Eastern Standard Tribe  |  Similarity: 0.7091\n",
      "10. Agar Halfi the mystic  |  Similarity: 0.7087\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "def recommend_books(title, k=10):\n",
    "    matches = df[df[\"title\"].str.lower().str.contains(title.lower(), na=False)]\n",
    "    \n",
    "    if matches.empty:\n",
    "        print(\"No matching title found.\")\n",
    "        return\n",
    "    \n",
    "    idx = matches.index[0]\n",
    "    \n",
    "    print(\"\\nSelected Book:\")\n",
    "    print(df.iloc[idx][\"title\"])\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(\"\\nModel A (TF-IDF + KNN) Recommendations:\\n\")\n",
    "    rec_indices_a = indices_a[idx][1:k+1]\n",
    "    for i, rec_idx in enumerate(rec_indices_a):\n",
    "        print(f\"{i+1}. {df.iloc[rec_idx]['title']}  |  Similarity: {similarities_a[idx][i]:.4f}\")\n",
    "    \n",
    "    print(\"\\nModel B (SVD + KNN) Recommendations:\\n\")\n",
    "    rec_indices_b = indices_b[idx][1:k+1]\n",
    "    for i, rec_idx in enumerate(rec_indices_b):\n",
    "        print(f\"{i+1}. {df.iloc[rec_idx]['title']}  |  Similarity: {similarities_b[idx][i]:.4f}\")\n",
    "\n",
    "\n",
    "title=input(\"Enter a book name: \")\n",
    "recommend_books(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8d77602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\models\\\\tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn_tfidf, r\"..\\models\\knn_tfidf.pkl\")\n",
    "joblib.dump(tfidf_vectorizer, r\"..\\models\\tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72dd77a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Book found in dataset:\n",
      "Pride and Prejudice\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "1. Pride and Prejudice, a play founded on Jane Austen's novel  | Similarity: 0.3819\n",
      "2. Sense and Sensibility  | Similarity: 0.3582\n",
      "3. Persuasion  | Similarity: 0.3480\n",
      "4. The Complete Project Gutenberg Works of Jane Austen: A Linked Index of all PG Editions of Jane Austen  | Similarity: 0.3370\n",
      "5. Northanger Abbey  | Similarity: 0.3235\n",
      "6. Jane Eyre  | Similarity: 0.2876\n",
      "7. Jane Eyre: An Autobiography  | Similarity: 0.2869\n",
      "8. Jane Austen and her works  | Similarity: 0.2840\n",
      "9. Love and Freindship [sic]  | Similarity: 0.2753\n",
      "10. Emma  | Similarity: 0.2748\n"
     ]
    }
   ],
   "source": [
    "def find_book(title_input):\n",
    "    title_input = title_input.lower().strip()\n",
    "    \n",
    "    exact_match = df[df[\"title\"].str.lower() == title_input]\n",
    "    if not exact_match.empty:\n",
    "        return exact_match.index.tolist()\n",
    "    \n",
    "    partial_match = df[df[\"title\"].str.lower().str.contains(title_input, na=False)]\n",
    "    if not partial_match.empty:\n",
    "        return partial_match.index.tolist()\n",
    "    \n",
    "    return []\n",
    "\n",
    "def recommend_existing(idx, k=10):\n",
    "    distances, indices = knn_tfidf.kneighbors(tfidf_sparse[idx], n_neighbors=k+1)\n",
    "\n",
    "    similarities = 1 - distances[0][1:]\n",
    "    rec_indices = indices[0][1:]\n",
    "    \n",
    "    print(\"\\nRecommendations:\\n\")\n",
    "    for i, rec_idx in enumerate(rec_indices):\n",
    "        print(f\"{i+1}. {df.iloc[rec_idx]['title']}  | Similarity: {similarities[i]:.4f}\")\n",
    "\n",
    "def recommend_new(title, summary, k=10):\n",
    "    words = summary.split()\n",
    "    if len(words) > 300:\n",
    "        summary = \" \".join(words[:300])\n",
    "    \n",
    "    combined_text = (title + \" \" + summary).lower()\n",
    "    new_vector = vectorizer.transform([combined_text])\n",
    "    \n",
    "    distances, indices = knn_model.kneighbors(new_vector, n_neighbors=k)\n",
    "    similarities = 1 - distances[0]\n",
    "    \n",
    "    print(\"\\nRecommendations:\\n\")\n",
    "    for i, rec_idx in enumerate(indices[0]):\n",
    "        print(f\"{i+1}. {df.iloc[rec_idx]['title']}  | Similarity: {similarities[i]:.4f}\")\n",
    "\n",
    "def run_recommender():\n",
    "    title_input = input(\"Enter book title: \").strip()\n",
    "    \n",
    "    matches = find_book(title_input)\n",
    "    \n",
    "    if len(matches) == 1:\n",
    "        print(\"\\nBook found in dataset:\")\n",
    "        print(df.iloc[matches[0]][\"title\"])\n",
    "        recommend_existing(matches[0])\n",
    "    \n",
    "    elif len(matches) > 1:\n",
    "        print(\"\\nMultiple matches found:\\n\")\n",
    "        for i, idx in enumerate(matches[:10]):\n",
    "            print(f\"{i+1}. {df.iloc[idx]['title']}\")\n",
    "        \n",
    "        choice = input(\"\\nSelect book number: \").strip()\n",
    "        \n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(matches[:10]):\n",
    "            selected_idx = matches[int(choice)-1]\n",
    "            recommend_existing(selected_idx)\n",
    "        else:\n",
    "            print(\"Invalid selection.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nBook not found in dataset.\")\n",
    "        summary = input(\"Enter short summary (max 300 words): \").strip()\n",
    "        recommend_new(title_input, summary)\n",
    "\n",
    "run_recommender()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
